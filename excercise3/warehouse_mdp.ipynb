{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2 - Warehouse MDP\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "import datetime\n",
    "import itertools\n",
    "import mdptoolbox\n",
    "import gc\n",
    "import pandas as pd\n",
    "from enum import IntEnum, Enum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enums for representing elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Color(IntEnum):\n",
    "    WHITE = 0\n",
    "    BLUE = 1\n",
    "    RED = 2\n",
    "\n",
    "class OccupancyType(IntEnum):\n",
    "    WHITE = 0\n",
    "    BLUE = 1\n",
    "    RED = 2\n",
    "    EMPTY = 3\n",
    "\n",
    "class InputAction(Enum):\n",
    "    STORE = 0\n",
    "    RESTORE = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Input\n",
    "Input describes the combination of an Inputaction (e.g. Store) and a Color (e.g. white)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Input:\n",
    "    def __init__(self, input_action:InputAction, color:Color):\n",
    "        self.input_action = input_action\n",
    "        self.color = color\n",
    "\n",
    "    def get_id(self):\n",
    "        return len(Color) * self.input_action.value + self.color.value\n",
    "\n",
    "    def print(self):\n",
    "        print(\"inputaction: {} - color: {}\".format(self.input_action, self.color))\n",
    "\n",
    "    @staticmethod\n",
    "    def combinations():\n",
    "        return list(itertools.product(InputAction, Color))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Action\n",
    "Describes the action that can be done in the warehouse. X and Y are the axis and start by 1 up to height and length described in the warehouse class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Action:\n",
    "    def __init__(self, pos_x:int, pos_y:int):\n",
    "        self.pos_x = pos_x\n",
    "        self.pos_y = pos_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Occupancy\n",
    "Represents the state of the warehouse occupancy. An action combined with an input can be performed on this state, which returns a new state of the warehouse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Occupancy:\n",
    "    def __init__(self, height:int, length: int):\n",
    "        self.state = [OccupancyType.EMPTY] * (height * length)\n",
    "        self.length = length\n",
    "\n",
    "    def perform_action(self, action:Action, input:Input):\n",
    "        new_occ = copy.deepcopy(self)\n",
    "        index = (action.pos_x-1) * new_occ.length + (action.pos_y - 1)\n",
    "        error = False\n",
    "\n",
    "        if input.input_action == InputAction.STORE:\n",
    "            if (new_occ.state[index] != OccupancyType.EMPTY):\n",
    "                error = True\n",
    "            new_occ.state[index] = OccupancyType(input.color)\n",
    "        else:\n",
    "            if new_occ.state[index] != input.color:\n",
    "                error = True\n",
    "            new_occ.state[index] = OccupancyType.EMPTY\n",
    "        return new_occ, error\n",
    "\n",
    "    def combinations(self):\n",
    "        return list(itertools.product(OccupancyType, repeat=len(self.state)))\n",
    "\n",
    "    def get_id(self):\n",
    "        id = 0\n",
    "        for index in range(0, len(self.state)):\n",
    "            id += np.power(len(OccupancyType), index) * self.state[index]\n",
    "        return id;\n",
    "\n",
    "    def print(self):\n",
    "        print(\"[\")\n",
    "        for x in self.state:\n",
    "            print(x)\n",
    "        print(\"]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Warehouse\n",
    "Combines the previous given class into one. Furthermore gives an entrance point for creating a warehouse with a given length/height. Sums up in his members lists of possible inputs, possible actions, and valid states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WareHouse:\n",
    "    def __init__(self, rows:int, columns: int):\n",
    "        self.rows = rows\n",
    "        self.columns = columns\n",
    "        self.inputs = self.create_all_inputs()\n",
    "        self.actions = self.create_all_actions()\n",
    "        self.states = self.create_only_logical_states()\n",
    "\n",
    "    def get_occupancy_length(self):\n",
    "        return self.rows * self.columns\n",
    "\n",
    "    def create_all_inputs(self):\n",
    "        inputs = []\n",
    "        for ia in InputAction:\n",
    "            for c in Color:\n",
    "                new_input = Input(ia, c)\n",
    "                inputs.append(new_input)\n",
    "        return inputs\n",
    "\n",
    "    def create_all_actions(self):\n",
    "        actions = []\n",
    "        for r in range(1, self.rows + 1):\n",
    "            for c in range(1, self.columns + 1):\n",
    "                actions.append(Action(r,c))\n",
    "        return actions\n",
    "\n",
    "    def create_only_logical_states(self):\n",
    "        logical_states = []\n",
    "        states = self.create_all_states()\n",
    "        self.state_row_dictionary = {}\n",
    "        rowIndex = 0\n",
    "        for state in states:\n",
    "            if state.is_state_logical():\n",
    "                logical_states.append(state)\n",
    "                self.state_row_dictionary[state.get_id()] = rowIndex\n",
    "                rowIndex += 1\n",
    "        return logical_states\n",
    "\n",
    "    def create_all_states(self):\n",
    "        self.state_row_dictionary = {}\n",
    "        list = []\n",
    "        inputs = Input.combinations()\n",
    "        sample = self.create_empty_occupancy()\n",
    "        occs = sample.combinations()\n",
    "        rowIndex = 0\n",
    "        for occ in occs:\n",
    "            for input in inputs:\n",
    "                occupancy = self.create_defined_occupancy(np.array(occ))\n",
    "                inp = Input(input[0], input[1])\n",
    "                s = State(self, occupancy, inp)\n",
    "                list.append(s)\n",
    "                self.state_row_dictionary[s.get_id()] = rowIndex\n",
    "                rowIndex += 1\n",
    "        return list\n",
    "\n",
    "    def create_empty_occupancy(self):\n",
    "        occ = Occupancy(self.rows, self.columns)\n",
    "        return occ\n",
    "\n",
    "    def create_defined_occupancy(self, state:[OccupancyType]):\n",
    "        occ = self.create_empty_occupancy()\n",
    "        occ.state = state\n",
    "        return occ\n",
    "\n",
    "    def get_possible_occupancy_count(self):\n",
    "        return np.power(len(OccupancyType), self.get_occupancy_length())\n",
    "\n",
    "    def get_states_count(self):\n",
    "        return len(self.states)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Orderfile\n",
    "Represents the training and test file. Calculates statistics to get a more specific transition matrix or more specific rewards. Additionally transforms each statement in the file into an instance of Input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OrderFile:\n",
    "\n",
    "    def __init__(self, filename:str):\n",
    "        length = len(Input.combinations())\n",
    "        self.matrix = np.zeros((length, length))\n",
    "        self.count = {}\n",
    "        self.count_sum = 0\n",
    "        self.duration = {}\n",
    "        self.inputs = self.read_file(filename)\n",
    "        return\n",
    "\n",
    "    def get_frequency_of_color(self, color:Color):\n",
    "        return self.count[color] / self.count_sum\n",
    "\n",
    "    #returns the percentage how much the given color has a longer duration than the minimum duration color\n",
    "    def get_duration_ratio(self, color:Color):\n",
    "        lowest = min(self.duration.values())\n",
    "        ratio = (self.duration[color] / lowest) - 1\n",
    "        return ratio\n",
    "\n",
    "    def create_statistic(self, inputs:[Input]):\n",
    "        duration_count = {\n",
    "            Color.WHITE: 0,\n",
    "            Color.BLUE: 0,\n",
    "            Color.RED: 0\n",
    "        }\n",
    "        duration_lists = {\n",
    "            Color.WHITE : [],\n",
    "            Color.BLUE : [],\n",
    "            Color.RED : []\n",
    "        }\n",
    "        storage_count = {\n",
    "            Color.WHITE: 0,\n",
    "            Color.BLUE: 0,\n",
    "            Color.RED: 0\n",
    "        }\n",
    "        prev_input:Input = None\n",
    "        for input in inputs:\n",
    "\n",
    "            if prev_input != None:\n",
    "                self.matrix[prev_input.get_id(), input.get_id()] += 1\n",
    "            prev_input = input\n",
    "\n",
    "            if(input.input_action == InputAction.STORE):\n",
    "                if input.color not in self.count:\n",
    "                    self.count[input.color] = 0\n",
    "                self.count[input.color] += 1\n",
    "                self.count_sum += 1\n",
    "                storage_count[input.color] += 1\n",
    "\n",
    "            else:\n",
    "                storage_count[input.color] -= 1\n",
    "                if storage_count[input.color] == 0:\n",
    "                    duration_lists[input.color].append(duration_count[input.color])\n",
    "                    duration_count[input.color] = 0\n",
    "\n",
    "            for key in storage_count:\n",
    "                if storage_count[key] != 0:\n",
    "                    duration_count[key] += 1\n",
    "\n",
    "        for key in duration_lists:\n",
    "            self.duration[key] = np.mean(duration_lists[key])\n",
    "\n",
    "    def read_file(self, filename:str):\n",
    "        inputs = []\n",
    "        with open(filename, 'r') as file:\n",
    "            for line in file:\n",
    "                split = line.rstrip().split(\"\\t\")\n",
    "                inputAction = InputAction[split[0].upper()]\n",
    "                color = Color[split[1].upper()]\n",
    "                inputs.append(Input(inputAction, color))\n",
    "        self.create_statistic(inputs)\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class State\n",
    "Defines a state in the given scenario. Its members are the warehouse itself, the occupancy and the given input. There various methods to get the next states with the given parameters. These function always return states and errors. Errors are true if the state is not valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State:\n",
    "    def __init__(self, warehouse:WareHouse, occupancy:Occupancy, input:Input):\n",
    "        self.warehouse = warehouse\n",
    "        self.occupancy = occupancy\n",
    "        self.input = input\n",
    "\n",
    "    def get_next_state(self, action:Action, new_input:Input):\n",
    "        #state_copy = copy.deepcopy(self)\n",
    "        state_copy = State(self.warehouse, self.occupancy, new_input)\n",
    "        new_occupancy, error = state_copy.occupancy.perform_action(action, self.input)\n",
    "        state_copy.occupancy = new_occupancy\n",
    "        if not error:\n",
    "            if not state_copy.is_state_logical():\n",
    "                error = True\n",
    "        return state_copy, error\n",
    "\n",
    "    def get_next_states(self, action:Action):\n",
    "        new_states = []\n",
    "        errors = []\n",
    "        for new_input in self.warehouse.inputs:\n",
    "            new_state, error = self.get_next_state(action, new_input)\n",
    "            new_states.append(new_state)\n",
    "            errors.append(error)\n",
    "        return new_states, errors\n",
    "\n",
    "    def get_next_possible_states(self, action:Action):\n",
    "        new_states = []\n",
    "        new_errors = []\n",
    "        all_states, all_errors = self.get_next_states(action)\n",
    "        for i in range(0, len(all_errors)):\n",
    "            if(all_errors[i] != True):\n",
    "                new_states.append(all_states[i])\n",
    "                new_errors.append(all_errors[i])\n",
    "        return new_states\n",
    "\n",
    "    def get_all_next_states(self):\n",
    "        new_states = []\n",
    "        new_errors = []\n",
    "        for action in self.warehouse.actions:\n",
    "            states, errors = self.get_next_states(action)\n",
    "            for i in range(0, len(errors)):\n",
    "                new_states.append(states[i])\n",
    "                new_errors.append(errors[i])\n",
    "        return new_states, new_errors\n",
    "\n",
    "    def get_id(self):\n",
    "        id_occ = self.occupancy.get_id()\n",
    "        id_input = self.input.get_id()\n",
    "        return id_occ + self.warehouse.get_possible_occupancy_count() * id_input\n",
    "\n",
    "    def print(self):\n",
    "        self.occupancy.print()\n",
    "        self.input.print()\n",
    "\n",
    "    def is_state_logical(self):\n",
    "        hasEmpty = False\n",
    "        completeEmpty = True\n",
    "        for occ in self.occupancy.state:\n",
    "            if occ == OccupancyType.EMPTY:\n",
    "                hasEmpty = True\n",
    "            else:\n",
    "                completeEmpty = False\n",
    "\n",
    "        # all impossible scenarios\n",
    "        if (self.input.input_action == InputAction.STORE) and (hasEmpty == False):\n",
    "            return False\n",
    "\n",
    "        if self.input.input_action == InputAction.RESTORE:\n",
    "            if (completeEmpty == True):\n",
    "                return False\n",
    "            if not (self.input.color in self.occupancy.state):\n",
    "                return False\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Probabilities\n",
    "Sums up static methods for providing probabilites given the current state and its possible states in future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Probabilities:\n",
    "    @staticmethod\n",
    "    def get_probability_equal(current_state:State, possible_states:[State], order_file:OrderFile):\n",
    "        #first of all let's try equal probabilities for each userinput\n",
    "        list = []\n",
    "        prob = round(1.0/len(possible_states), 4)\n",
    "        for state in possible_states:\n",
    "            t = (state, prob)\n",
    "            list.append(t)\n",
    "        return list\n",
    "\n",
    "    @staticmethod\n",
    "    def get_probability_by_distribution(current_state:State, possible_states:[State], order_file:OrderFile):\n",
    "        if orderFile == None:\n",
    "            return Probabilities.get_probability_equal(current_state, possible_states, None)\n",
    "\n",
    "        values = []\n",
    "        sum = 0\n",
    "        for state in possible_states:\n",
    "            val = order_file.matrix[current_state.input.get_id(), state.input.get_id()]\n",
    "            values.append((state, val))\n",
    "            sum += val\n",
    "        tuples = []\n",
    "        for (state, value) in values:\n",
    "            prob = value / sum\n",
    "            prob = round(prob, 4)\n",
    "            t = (state, prob)\n",
    "            tuples.append(t)\n",
    "\n",
    "        return tuples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Rewards\n",
    "Represents a reward matrix. Calculates the entries with a distance function for the action combined with the frequency of a color and the duration of a color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rewards:\n",
    "    def __init__(self, states_count:int, actions:[Action], order_file:OrderFile):\n",
    "        self.matrix = np.zeros((states_count, len(actions)))\n",
    "        self.order_file = order_file\n",
    "        self.actions = actions\n",
    "\n",
    "    def get_reward(self, current_state:State, action:Action, frequency:bool=True, duration:bool=True):\n",
    "        possible_states = current_state.get_next_possible_states(action)\n",
    "\n",
    "        if len(possible_states) == 0:\n",
    "            return -10\n",
    "\n",
    "        #simple evaluation of the distance the action would bring\n",
    "        distance_value = self.get_distance_action_reward(current_state, action) * 10\n",
    "\n",
    "        #combine with frequency & duration of color\n",
    "        frequency = self.order_file.get_frequency_of_color(current_state.input.color) * 3\n",
    "        duration = self.order_file.get_duration_ratio(current_state.input.color)\n",
    "\n",
    "        #distance value is the most important influence on the reward\n",
    "        #the higher the frequency of a color the higher should be the overall value\n",
    "        #the longer the duration of the color the lower should be the overall value\n",
    "        overall_value = distance_value \\\n",
    "\n",
    "        if frequency:\n",
    "            overall_value += frequency * distance_value \\\n",
    "\n",
    "        if duration:\n",
    "            overall_value -= duration * distance_value\n",
    "\n",
    "        return round(overall_value)\n",
    "\n",
    "    #returns between 0 and height*length-1, the more the better\n",
    "    def get_distance_action_reward(self, current_state:State, action:Action):\n",
    "        x = action.pos_x\n",
    "        y = action.pos_y\n",
    "        calculated_factor = x*y\n",
    "        max = current_state.warehouse.rows * current_state.warehouse.columns\n",
    "        return (max - calculated_factor)\n",
    "\n",
    "    def calculate_matrix(self, list:[State], state_row_dict, frequency:bool=True, duration:bool=True):\n",
    "        for state in list:\n",
    "            i = 0\n",
    "            for action in self.actions:\n",
    "                reward = self.get_reward(state, action)\n",
    "                row_index = state_row_dict[state.get_id()]\n",
    "                self.matrix[row_index, i] = reward\n",
    "                i += 1\n",
    "        return self.matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class TransitionMatrix\n",
    "Represents a transitionmatrix. Calculates the matrix with the given probability function. Simply goes through each possible states, calculates future states and saves the probability of each in the matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransitionMatrix:\n",
    "    def __init__(self, states_count:int, action:Action):\n",
    "        #initialize transition matrix with zeros first\n",
    "        self.matrix = np.zeros((states_count, states_count))\n",
    "        self.action = action\n",
    "\n",
    "    def calculate_matrix(self, list:[State], state_row_dict, probability_function, order_file:OrderFile):\n",
    "        for state in list:\n",
    "            id = state.get_id()\n",
    "            row_index = state_row_dict[id]\n",
    "            next_states = state.get_next_possible_states(self.action)\n",
    "            if not next_states:\n",
    "                #no further step with this state so probability is 1 for staying in this state\n",
    "                self.matrix[row_index, row_index] = 1\n",
    "            else:\n",
    "                # set probabilities for this specific action in this state\n",
    "                probabilitíes = probability_function(state, next_states, order_file)\n",
    "                for (state2, prob) in probabilitíes:\n",
    "                    id2 = state2.get_id()\n",
    "                    if id2 in state_row_dict.keys():\n",
    "                        row_index2 = state_row_dict[id2]\n",
    "                        self.matrix[row_index, row_index2] = prob\n",
    "\n",
    "    def check_fullfillment(self):\n",
    "        x = 0\n",
    "        y = 0\n",
    "        for row in self.matrix:\n",
    "            sum = np.sum(row)\n",
    "            if(sum != 1):\n",
    "                #fix for floating issues\n",
    "                delta = 1 - sum\n",
    "                if(delta > 0.1):\n",
    "                    return False\n",
    "                else:\n",
    "                    y = 0\n",
    "                    for column in row:\n",
    "                        if column > 0:\n",
    "                            self.matrix[x, y] += delta\n",
    "                            break\n",
    "                        y += 1\n",
    "            x += 1\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Evaluation\n",
    "Calculates the total costs with a given policy and Orderfile. Seperate function provides the costs for the greedy function, that simply takes always the first spot in the warehouse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Evaluation:\n",
    "    def __init__(self, warehouse: WareHouse, train_file: OrderFile, policy: tuple):\n",
    "        self.inputs = train_file.inputs\n",
    "        self.warehouse = warehouse\n",
    "        self.policy = policy\n",
    "\n",
    "    def calculate_costs(self):\n",
    "        empty = warehouse.create_empty_occupancy()\n",
    "        state = State(warehouse, empty, self.inputs[0])\n",
    "        costs = 0\n",
    "\n",
    "        for input in self.inputs[1:]:\n",
    "            # state.print()\n",
    "            state_row_index = warehouse.state_row_dictionary[state.get_id()]\n",
    "            action_id = self.policy[state_row_index]\n",
    "            action = self.warehouse.actions[action_id]\n",
    "            state, _ = state.get_next_state(action, input)\n",
    "            # calc costs - way to the spot and back again\n",
    "            costs += self.cost(action)\n",
    "\n",
    "        state_row_index = warehouse.state_row_dictionary[state.get_id()]\n",
    "        action_id = self.policy[state_row_index]\n",
    "        action = self.warehouse.actions[action_id]\n",
    "        costs += self.cost(action)\n",
    "        mean = costs / len(self.inputs)\n",
    "        return costs, mean\n",
    "\n",
    "    def calculate_greedy(self):\n",
    "        empty = warehouse.create_empty_occupancy()\n",
    "        state = State(warehouse, empty, self.inputs[0])\n",
    "        costs = 0\n",
    "\n",
    "        for input in self.inputs[1:]:\n",
    "            # state.print()\n",
    "            for action in warehouse.actions:\n",
    "                new_state, error = state.get_next_state(action, input)\n",
    "                if not error:\n",
    "                    state = new_state\n",
    "                    costs += self.cost(action)\n",
    "                    break\n",
    "\n",
    "        for action in warehouse.actions:\n",
    "            _, error = state.get_next_state(action, self.inputs[0])\n",
    "            if not error:\n",
    "                costs += self.cost(action)\n",
    "                break\n",
    "\n",
    "        mean = costs / len(self.inputs)\n",
    "        return costs, mean\n",
    "\n",
    "    def cost(self, action: Action):\n",
    "        return (action.pos_y - 1 + action.pos_x) * 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finally: Creation of the policies and printing the results:\n",
    "Iterates through each config and with each config it calculates a policy for each algorithm. Prints out the result with the evaluation class. Each cell the agent has to move is defined with cost 1 (return included)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== RESULTS ===\n",
      "Transition matrix:  Distribution of the training set\n",
      "Frequency of color in rewards:  True\n",
      "Duration of color in rewards:  True\n",
      "Algorithm:  ValueIteration\n",
      "Sum =  248  - Mean =  4.133333333333334\n",
      "Algorithm:  RelativeValueIteration\n",
      "Sum =  256  - Mean =  4.266666666666667\n",
      "Algorithm:  ValueIterationGS\n",
      "Sum =  248  - Mean =  4.133333333333334\n",
      "Algorithm: Greedy\n",
      "Sum =  260  - Mean =  4.333333333333333\n",
      "===========================\n",
      "  \n",
      "Transition matrix:  Equally Distributed\n",
      "Frequency of color in rewards:  True\n",
      "Duration of color in rewards:  True\n",
      "Algorithm:  ValueIteration\n",
      "Sum =  248  - Mean =  4.133333333333334\n",
      "Algorithm:  RelativeValueIteration\n",
      "Sum =  252  - Mean =  4.2\n",
      "Algorithm:  ValueIterationGS\n",
      "Sum =  248  - Mean =  4.133333333333334\n",
      "Algorithm: Greedy\n",
      "Sum =  260  - Mean =  4.333333333333333\n",
      "===========================\n",
      "  \n",
      "Transition matrix:  Distribution of the training set\n",
      "Frequency of color in rewards:  False\n",
      "Duration of color in rewards:  True\n",
      "Algorithm:  ValueIteration\n",
      "Sum =  248  - Mean =  4.133333333333334\n",
      "Algorithm:  RelativeValueIteration\n",
      "Sum =  256  - Mean =  4.266666666666667\n",
      "Algorithm:  ValueIterationGS\n",
      "Sum =  248  - Mean =  4.133333333333334\n",
      "Algorithm: Greedy\n",
      "Sum =  260  - Mean =  4.333333333333333\n",
      "===========================\n",
      "  \n",
      "Transition matrix:  Equally Distributed\n",
      "Frequency of color in rewards:  False\n",
      "Duration of color in rewards:  True\n",
      "Algorithm:  ValueIteration\n",
      "Sum =  248  - Mean =  4.133333333333334\n",
      "Algorithm:  RelativeValueIteration\n",
      "Sum =  252  - Mean =  4.2\n",
      "Algorithm:  ValueIterationGS\n",
      "Sum =  248  - Mean =  4.133333333333334\n",
      "Algorithm: Greedy\n",
      "Sum =  260  - Mean =  4.333333333333333\n",
      "===========================\n",
      "  \n",
      "Transition matrix:  Distribution of the training set\n",
      "Frequency of color in rewards:  True\n",
      "Duration of color in rewards:  False\n",
      "Algorithm:  ValueIteration\n",
      "Sum =  248  - Mean =  4.133333333333334\n",
      "Algorithm:  RelativeValueIteration\n",
      "Sum =  256  - Mean =  4.266666666666667\n",
      "Algorithm:  ValueIterationGS\n",
      "Sum =  248  - Mean =  4.133333333333334\n",
      "Algorithm: Greedy\n",
      "Sum =  260  - Mean =  4.333333333333333\n",
      "===========================\n",
      "  \n",
      "Transition matrix:  Equally Distributed\n",
      "Frequency of color in rewards:  True\n",
      "Duration of color in rewards:  False\n",
      "Algorithm:  ValueIteration\n",
      "Sum =  248  - Mean =  4.133333333333334\n",
      "Algorithm:  RelativeValueIteration\n",
      "Sum =  252  - Mean =  4.2\n",
      "Algorithm:  ValueIterationGS\n",
      "Sum =  248  - Mean =  4.133333333333334\n",
      "Algorithm: Greedy\n",
      "Sum =  260  - Mean =  4.333333333333333\n",
      "===========================\n",
      "  \n",
      "Transition matrix:  Distribution of the training set\n",
      "Frequency of color in rewards:  False\n",
      "Duration of color in rewards:  False\n",
      "Algorithm:  ValueIteration\n",
      "Sum =  248  - Mean =  4.133333333333334\n",
      "Algorithm:  RelativeValueIteration\n",
      "Sum =  256  - Mean =  4.266666666666667\n",
      "Algorithm:  ValueIterationGS\n",
      "Sum =  248  - Mean =  4.133333333333334\n",
      "Algorithm: Greedy\n",
      "Sum =  260  - Mean =  4.333333333333333\n",
      "===========================\n",
      "  \n",
      "Transition matrix:  Equally Distributed\n",
      "Frequency of color in rewards:  False\n",
      "Duration of color in rewards:  False\n",
      "Algorithm:  ValueIteration\n",
      "Sum =  248  - Mean =  4.133333333333334\n",
      "Algorithm:  RelativeValueIteration\n",
      "Sum =  252  - Mean =  4.2\n",
      "Algorithm:  ValueIterationGS\n",
      "Sum =  248  - Mean =  4.133333333333334\n",
      "Algorithm: Greedy\n",
      "Sum =  260  - Mean =  4.333333333333333\n",
      "===========================\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#main code\n",
    "variations = list(itertools.product([True, False], repeat=3))\n",
    "print(\"=== RESULTS ===\")\n",
    "\n",
    "for (duration, frequency, prob) in variations:\n",
    "    orderFile = OrderFile(\"warehousetraining.txt\")\n",
    "    testFile = OrderFile(\"warehouseorder.txt\")\n",
    "    warehouse = WareHouse(2, 3)\n",
    "\n",
    "    #calculate reward matrix#\n",
    "    #print(len(warehouse.states))\n",
    "    #print(\"Create Reward\")\n",
    "    #print(\"Start: \", datetime.datetime.now())\n",
    "    reward = Rewards(warehouse.get_states_count(), warehouse.actions, orderFile)\n",
    "    rmatrix = reward.calculate_matrix(warehouse.states, warehouse.state_row_dictionary, frequency=frequency, duration=duration)\n",
    "    rmatrix = rmatrix.astype(np.int8)\n",
    "    #print(\"End: \", datetime.datetime.now())\n",
    "\n",
    "    #calculate transition for each action\n",
    "    #print(\"Create Transitions\")\n",
    "    #print(\"Start: \", datetime.datetime.now())\n",
    "    trans = np.zeros((len(warehouse.actions), len(warehouse.states), len(warehouse.states)), dtype=np.float16)\n",
    "    i = 0\n",
    "    for action in warehouse.actions:\n",
    "        matrix = TransitionMatrix(warehouse.get_states_count(), action)\n",
    "        if(prob):\n",
    "            matrix.calculate_matrix(warehouse.states, warehouse.state_row_dictionary, Probabilities.get_probability_by_distribution, orderFile)\n",
    "        else:\n",
    "            matrix.calculate_matrix(warehouse.states, warehouse.state_row_dictionary, Probabilities.get_probability_equal, orderFile)\n",
    "\n",
    "        matrix.check_fullfillment()\n",
    "        trans[i] = matrix.matrix.astype(np.float16)\n",
    "        del(matrix)\n",
    "        i += 1\n",
    "    #print(\"End: \", datetime.datetime.now())\n",
    "\n",
    "    #create and train value iteration\n",
    "    #print(\"Train\")\n",
    "    #print(\"Start: \", datetime.datetime.now())\n",
    "    policies = []\n",
    "    names = []\n",
    "    for x in range(3):\n",
    "        if x == 0:\n",
    "            names.append(\"ValueIteration\")\n",
    "            alg = mdptoolbox.mdp.ValueIteration(trans, rmatrix, 0.3, max_iter=100)\n",
    "        if x == 1:\n",
    "            names.append(\"RelativeValueIteration\")\n",
    "            alg = mdptoolbox.mdp.RelativeValueIteration(trans, rmatrix, max_iter=100)\n",
    "        if x == 2:\n",
    "            names.append(\"ValueIterationGS\")\n",
    "            alg = mdptoolbox.mdp.ValueIterationGS(trans, rmatrix, 0.3)\n",
    "        alg.run()\n",
    "        policies.append(alg.policy)\n",
    "        del(alg)\n",
    "\n",
    "    prob_name = \"Distribution of the training set\" if prob else \"Equally Distributed\"\n",
    "    print(\"Transition matrix: \", prob_name)\n",
    "    print(\"Frequency of color in rewards: \", frequency)\n",
    "    print(\"Duration of color in rewards: \", duration)\n",
    "    costs_greedy = 0\n",
    "    mean_greedy = 0\n",
    "    for x in range(3):\n",
    "        print(\"Algorithm: \", names[x])\n",
    "        eval = Evaluation(warehouse, testFile, policies[x])\n",
    "        costs_value, mean_value = eval.calculate_costs()\n",
    "        costs_greedy, mean_greedy = eval.calculate_greedy()\n",
    "        del(eval)\n",
    "        print('Sum = ', costs_value, ' - Mean = ', mean_value)\n",
    "    print(\"Algorithm: Greedy\")\n",
    "    print('Sum = ', costs_greedy, ' - Mean = ', mean_greedy)\n",
    "    print(\"===========================\")\n",
    "    print(\"  \")\n",
    "\n",
    "    del(policies)\n",
    "    del(names)\n",
    "    del(trans)\n",
    "    del(rmatrix)\n",
    "    del(reward)\n",
    "    del(warehouse)\n",
    "    del(testFile)\n",
    "    del(orderFile)\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
